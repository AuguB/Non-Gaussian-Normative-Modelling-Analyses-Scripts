{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3df106a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pcntoolkit as ptk\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from pcntoolkit.util.hbr_utils import *\n",
    "import scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b3bf3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curdir='/project_cephfs/3022017.02/projects/stijdboe/make_results'\n",
      "processing_dir='/project_cephfs/3022017.02/projects/stijdboe/make_results/more_flexible_models_lifespan_big'\n"
     ]
    }
   ],
   "source": [
    "curdir = os.getcwd()\n",
    "processing_dirname = \"more_flexible_models_lifespan_big\"\n",
    "if not curdir.endswith(processing_dirname):\n",
    "    processing_dir = os.path.join(curdir,\"more_flexible_models_lifespan_big\")\n",
    "    if not os.path.isdir(processing_dir):\n",
    "        os.mkdir(processing_dir)\n",
    "    os.chdir(processing_dir)\n",
    "else:\n",
    "    curdir=os.path.dirname(processing_dir)\n",
    "    \n",
    "print(f\"{curdir=}\")\n",
    "print(f\"{processing_dir=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3f0154e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the lifespan_big data\n",
    "datadir = '/project_cephfs/3022017.02/projects/stijdboe/Data/UMAP_data/'\n",
    "respfile = os.path.join(datadir, 'trainselect.txt')       # measurements  (eg cortical thickness) of the training samples (columns: the various features/ROIs, rows: observations or subjects)\n",
    "covfile = os.path.join(datadir, 'cov_tr.txt')        # covariates (eg age) the training samples (columns: covariates, rows: observations or subjects)\n",
    "testrespfile_path = os.path.join(datadir, 'testselect.txt')       # measurements  for the testing samples\n",
    "testcovfile_path = os.path.join(datadir, 'cov_te.txt')        # covariate file for the testing samples\n",
    "# befile = os.path.join(datadir, 'Z_train.pkl')      # training batch effects file (eg scanner_id, gender)  (columns: the various batch effects, rows: observations or subjects)\n",
    "# testbefile = os.path.join(datadir, 'Z_test.pkl')      # testing batch effects file\n",
    "\n",
    "output_path = os.path.join(processing_dir, 'Models/')    #  output path, where the models will be written\n",
    "if not os.path.isdir(output_path):\n",
    "    os.mkdir(output_path)\n",
    "\n",
    "log_dir = os.path.join(processing_dir, 'log/')           #\n",
    "if not os.path.isdir(log_dir):\n",
    "    os.mkdir(log_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03ee9f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters shared by all models\n",
    "model_type='bspline'\n",
    "linear_mu='True'\n",
    "linear_sigma='True'\n",
    "random_intercept_mu='True'\n",
    "centered_intercept_mu='False'\n",
    "inscaler_type='standardize'\n",
    "outscaler_type='standardize'\n",
    "sampler = 'NUTS'\n",
    "n_mcmc_samples = 1\n",
    "n_tuning_samples = 1\n",
    "n_chains = 1\n",
    "n_cores = 1\n",
    "target_accept = 0.99\n",
    "alg='hbr'\n",
    "saveoutput='True'\n",
    "savemodel='True'\n",
    "binary='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c2f5997-2937-4e66-a8ed-8eb37d5f286e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.loadtxt(covfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d995529e-8801-4521-b1fc-b43500eb5af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.loadtxt(covfile)\n",
    "Y_train = np.loadtxt(respfile)\n",
    "trainselect = os.path.join(datadir,'trainselect.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a24d51d-90ff-442b-8cc6-0ee23f10fdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.loadtxt(testcovfile_path)\n",
    "Y_test = np.loadtxt(testrespfile_path)\n",
    "testselect = os.path.join(datadir,'testselect.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "544b0076-55ed-4a56-b9fc-b09f5f93616d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inscaler_type='standardize'\n",
    "outscaler_type='standardize'\n",
    "\n",
    "inscaler = ptk.util.utils.scaler(inscaler_type)\n",
    "X_train_standardized = inscaler.fit_transform(X_train)\n",
    "X_test_standardized = inscaler.transform(X_test)\n",
    "\n",
    "outscaler = ptk.util.utils.scaler(outscaler_type)\n",
    "Y_train_standardized = np.squeeze(outscaler.fit_transform(Y_train))\n",
    "Y_test_standardized = np.squeeze(outscaler.transform(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7148832-eac6-415c-90e6-c244e303d54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data in /project_cephfs/3022017.02/projects/stijdboe/Data/UMAP_data/trainselect.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_names = ['SHASHb_1','SHASHb_2','Normal']\n",
    "likelihood_map = {'SHASHb_1':'SHASHb','SHASHb_2':'SHASHb','Normal':'Normal'}\n",
    "durationmap = {'Normal':'05:00:00','SHASHb':'05:00:00'}\n",
    "epsilon_linear_map = {'SHASHb_1':'False','SHASHb_2':'True','Normal':'False'}\n",
    "delta_linear_map = {'SHASHb_1':'False','SHASHb_2':'True','Normal':'False'}\n",
    "# For each config\n",
    "\n",
    "for mn in model_names:\n",
    "    likelihood = likelihood_map[mn]\n",
    "    linear_epsilon = epsilon_linear_map[mn]\n",
    "    linear_delta = delta_linear_map[mn]\n",
    "    outputsuffix = f'UMAP_{mn}'\n",
    "    nm = ptk.normative.fit(covfile=covfile,\n",
    "                           respfile=trainselect,\n",
    "                           log_path=log_dir,\n",
    "                           saveoutput=saveoutput,\n",
    "                           output_path=output_path, \n",
    "                           savemodel=savemodel,\n",
    "                           binary=binary,\n",
    "                           outputsuffix=outputsuffix,\n",
    "                           alg=alg,\n",
    "                           sampler=sampler,\n",
    "                           n_samples=n_mcmc_samples,\n",
    "                           n_tuning=n_tuning_samples,\n",
    "                           n_chains=n_chains,\n",
    "                           cores=n_cores,\n",
    "                           target_accept=target_accept,\n",
    "                           inscaler=inscaler_type,\n",
    "                           outscaler=outscaler_type,\n",
    "                           likelihood=likelihood,\n",
    "                           model_type=model_type,\n",
    "                           linear_mu=linear_mu,\n",
    "                           random_intercept_mu=random_intercept_mu,\n",
    "                           centered_intercept_mu=centered_intercept_mu,\n",
    "                           linear_sigma=linear_sigma,\n",
    "                           linear_epsilon=linear_epsilon,\n",
    "                           linear_delta = linear_delta,\n",
    "                     )\n",
    "    MAP = nm.hbr.find_map(X_train_standardized, Y_train_standardized, np.zeros_like(Y_train_standardized))\n",
    "    with open(os.path.join(processing_dir, f'MAP_{outputsuffix}.pkl'),'wb') as file:\n",
    "        pickle.dump(MAP, file)\n",
    "    # Find and store the MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64b78d1-1a80-4010-b207-cb2f4e2654d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(processing_dir, f'Models/NM_0_0_lifespanRight-Lateral-VentricleSHASHbTrueTrue.pkl'),'rb') as file:\n",
    "    model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3bca3f-16d1-438e-99c2-21768c35acc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stijn1",
   "language": "python",
   "name": "stijn1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
